import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster

df = pd.read_csv(r"sales_data_sample.csv", encoding='latin1')
print(df.head())

print(df.info())

data = df[['QUANTITYORDERED', 'PRICEEACH', 'SALES']].dropna()

scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)


wcss = []

for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of clusters (k)')
plt.ylabel('WCSS')
plt.show()


kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)
y_kmeans = kmeans.fit_predict(scaled_data)

# Add cluster labels to the original data
data['Cluster'] = y_kmeans

plt.figure(figsize=(8,6))
sns.scatterplot(x='SALES', y='PRICEEACH', hue='Cluster', data=data, palette='tab10')
plt.title('K-Means Clustering on Sales Data')
plt.show()

linked = linkage(scaled_data, method='ward')

plt.figure(figsize=(10, 6))
dendrogram(linked)
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('Samples')
plt.ylabel('Distance')
plt.show()


cluster_summary = data.groupby('Cluster').mean()
print(cluster_summary)
